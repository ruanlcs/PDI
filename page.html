<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.22">
<meta name="author" content="Ruan Lucas">
<title>Exercícios: Processamento Digital de Imagens (DCA0445)</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.square{list-style-type:square}
ul.circle ul:not([class]),ul.disc ul:not([class]),ul.square ul:not([class]){list-style:inherit}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child{border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:first-child,.sidebarblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child,.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active,#footnotes .footnote a:first-of-type:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,td.hdlist1,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.3/styles/atom-one-light.min.css">
</head>
<body class="article toc2 toc-left">
<div id="header">
<h1>Exercícios: Processamento Digital de Imagens (DCA0445)</h1>
<div class="details">
<span id="author" class="author">Ruan Lucas</span><br>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Sumário</div>
<ul class="sectlevel1">
<li><a href="#_prefácio">Prefácio</a></li>
<li><a href="#_1_conceitos_iniciais">1. Conceitos Iniciais</a></li>
<li><a href="#_2_manipulando_pixels_em_uma_imagem">2. Manipulando pixels em uma imagem</a>
<ul class="sectlevel2">
<li><a href="#_2_1_negativo_de_uma_imagem">2.1 Negativo de uma imagem</a></li>
<li><a href="#_2_2_trocar_regiões">2.2 Trocar regiões</a></li>
</ul>
</li>
<li><a href="#_3_serialização_de_dados_em_ponto_flutuante_via_filestorage">3. Serialização de dados em ponto flutuante via FileStorage</a>
<ul class="sectlevel2">
<li><a href="#_3_1_exercício">3.1 Exercício</a></li>
</ul>
</li>
<li><a href="#_4_decomposição_de_imagens_digitais">4. Decomposição de imagens digitais</a>
<ul class="sectlevel2">
<li><a href="#_4_1_esteganografia">4.1 Esteganografia</a></li>
<li><a href="#_4_2_exercicio">4.2 Exercicio</a></li>
</ul>
</li>
<li><a href="#_5_preenchendo_regiões">5. Preenchendo regiões</a>
<ul class="sectlevel2">
<li><a href="#_5_1_exercicio">5.1 Exercicio</a></li>
<li><a href="#_5_2_exercicio">5.2 exercicio</a></li>
</ul>
</li>
<li><a href="#_6_manipulando_histogramas">6 Manipulando histogramas</a>
<ul class="sectlevel2">
<li><a href="#_6_1_equalização">6.1 Equalização</a></li>
<li><a href="#_6_2_detecção_de_movimento">6.2 Detecção de Movimento</a></li>
</ul>
</li>
<li><a href="#_7_filtragem_no_dominio_espacial_i">7 Filtragem no dominio espacial I</a>
<ul class="sectlevel2">
<li><a href="#_7_1_exercício">7.1 Exercício</a></li>
</ul>
</li>
<li><a href="#_8_filtragem_no_dominio_espacial_ii">8 Filtragem no dominio espacial II</a></li>
<li><a href="#_9_a_tranformada_discreta_de_fourier">9 A Tranformada Discreta de Fourier</a>
<ul class="sectlevel2">
<li><a href="#_exercicio_9_1">Exercicio 9.1</a></li>
<li><a href="#_exercicio_9_2">Exercicio 9.2</a></li>
<li><a href="#_exercicio_9_3">Exercicio 9.3</a></li>
</ul>
</li>
<li><a href="#_10_filtragem_no_domínio_da_frequência">10 Filtragem no Domínio da Frequência</a>
<ul class="sectlevel2">
<li><a href="#_exercicio">Exercicio</a></li>
</ul>
</li>
<li><a href="#_11_detecção_de_bordas_com_o_algoritmo_canny">11 Detecção de bordas com o algoritmo Canny</a>
<ul class="sectlevel2">
<li><a href="#_exercicio_2">Exercicio</a></li>
</ul>
</li>
<li><a href="#_12_quantização_vetorial_com_k_means">12 Quantização vetorial com K-means</a>
<ul class="sectlevel2">
<li><a href="#_exercicio_3">Exercicio</a></li>
</ul>
</li>
<li><a href="#_13_extração_de_contornos">13 Extração de contornos</a>
<ul class="sectlevel2">
<li><a href="#_exercicio_13_1">Exercicio 13.1</a></li>
<li><a href="#_exercicio_13_2">Exercicio 13.2</a></li>
</ul>
</li>
<li><a href="#_14_filtragem_de_forma_com_morfologia_matemática">14 Filtragem de forma com morfologia matemática</a>
<ul class="sectlevel2">
<li><a href="#_exercicio_4">Exercicio</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_prefácio">Prefácio</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Parte I: Processamento de Imagens no Dominío Espacial</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_1_conceitos_iniciais">1. Conceitos Iniciais</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Nesta página, abordaremos diversos conceitos ligados ao processamento de imagens no domínio espacial, com foco nas áreas de manipulação de imagens e histogramas, serialização de dados, decomposição de imagens, preenchimento de regiões e aplicação de métodos de filtragem.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_2_manipulando_pixels_em_uma_imagem">2. Manipulando pixels em uma imagem</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_2_1_negativo_de_uma_imagem">2.1 Negativo de uma imagem</h3>
<div class="paragraph">
<p>Esse programa deverá solicitar ao usuário as coordenadas de dois pontos P1 e P2 localizados dentro dos limites do tamanho da imagem e exibir que lhe for fornecida. Entretanto, a região definida pelo retângulo de vértices opostos definidos pelos pontos P1 e P2 será exibida com o negativo da imagem na região correspondente.</p>
</div>
<div class="sect3">
<h4 id="_solução">Solução</h4>
<div class="paragraph">
<p>A código a seguir realiza a aplicação de um efeito de negativo em uma região específica de uma imagem, a partir dos dados fornecidos pelo usuário.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Carrega uma imagem em escala de cinza e define as dimensões da imagem.</p>
</li>
<li>
<p>Solicita ao usuário as coordenadas P1 e P2 do retâgulo que define a região a ser negativa.</p>
</li>
<li>
<p>Verifica se as coordenadas iseridas são válidas.</p>
</li>
<li>
<p>Aplica o  efeito de negativo à região delimitada pelo retângulo.</p>
</li>
<li>
<p>Exibe e também salva a imagem resultante, que possui a região como negativo.</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2

def negative_region(image, p1, p2):
    # Criar uma cópia da imagem
    result = image.copy()

    # Obter as coordenadas do retângulo
    x_min, x_max = min(p1[0], p2[0]), max(p1[0], p2[0])
    y_min, y_max = min(p1[1], p2[1]), max(p1[1], p2[1])

    # Garantir que as coordenadas estejam dentro dos limites da imagem
    x_min = max(0, x_min)
    y_min = max(0, y_min)
    x_max = min(image.shape[1] - 1, x_max)
    y_max = min(image.shape[0] - 1, y_max)

    # Aplicar o negativo da imagem na região do retângulo
    result[y_min:y_max+1, x_min:x_max+1] = 255 - result[y_min:y_max+1, x_min:x_max+1]

    # Exibir a imagem resultante
    cv2.imshow("Imagem Negativa", result)
    cv2.imwrite("resultado.png", image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

# Carregar a imagem
image = cv2.imread("fib.png", cv2.IMREAD_GRAYSCALE)
if image is None:
    print("Não foi possível abrir a imagem.")
else:
    #Dimensão da imagem
    width = image.shape[1]
    height = image.shape[0]
    print(f"{width}x{height}")

    # Solicitar ao usuário as coordenadas de P1 e P2
    p1_x = int(input("Digite a coordenada X de P1: "))
    p1_y = int(input("Digite a coordenada Y de P1: "))

    # Verifica se P1 possui coordenadas válidas
    if p1_x &lt; 0 or p1_y &lt; 0 or p1_x &gt; image.shape[1] or p1_y &gt; image.shape[0]:
        print("\nInsira um ponto válido")
        exit(1)
    print("\nP1x e P1y são válidos. \n")
    p2_x = int(input("Digite a coordenada X de P2: "))
    p2_y = int(input("Digite a coordenada Y de P2: "))

    # Verifica se P2 possui coordenadas válidas
    if p2_x &lt; 0 or p2_y &lt; 0 or p2_x &gt; image.shape[1] or p2_y &gt; image.shape[0] or p2_x &lt;= p1_x or p2_y &lt;= p1_y:
        print("\nInsira um ponto válido")
        exit(1)
    print("\nP2x e P2y são válidos.")

    print("P1 e P2 são válidos.\n")

    negative_region(image, (p1_x, p1_y), (p2_x, p2_y))</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resultado">Resultado</h4>
<div class="imageblock">
<div class="content">
<img src="images/resultado.png" alt="resultado">
</div>
<div class="title">Figure 1. Imagem com negativo</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_2_trocar_regiões">2.2 Trocar regiões</h3>
<div class="paragraph">
<p>Seu programa deverá trocar os quadrantes em diagonal na imagem. Assuma que a imagem de entrada tem dimensões múltiplas de 2 para facilitar a implementação do processo de troca.</p>
</div>
<div class="sect3">
<h4 id="_solução_2">Solução</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Carrega a imagem &#8220;fib.png&#8221; em escala de cinza.</p>
</li>
<li>
<p>Divide a imagem em quatro quadrantes</p>
</li>
<li>
<p>Realiza a troca dos quadrantes</p>
<div class="ulist">
<ul>
<li>
<p>Troca o Quadrante 1 com o Quadrante 3.</p>
</li>
<li>
<p>Troca o Quadrante 2 com o Quadrante 4.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Salva e exibe a imagem resultante <code>regioes-trocadas.png</code></p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2

def carregar_imagem(nome_arquivo):
    imagem = cv2.imread(nome_arquivo, cv2.IMREAD_GRAYSCALE)
    if imagem is None:
        print("Não foi possível abrir a imagem")
        exit()
    return imagem

def dividir_quadrantes(imagem):
    altura, largura = imagem.shape[:2]
    metade_altura = altura // 2
    metade_largura = largura // 2
    quadrante_1 = imagem[0:metade_altura, 0:metade_largura].copy()
    quadrante_2 = imagem[0:metade_altura, metade_largura:largura].copy()
    quadrante_3 = imagem[metade_altura:altura, 0:metade_largura].copy()
    quadrante_4 = imagem[metade_altura:altura, metade_largura:largura].copy()
    return quadrante_1, quadrante_2, quadrante_3, quadrante_4

def trocar_quadrantes(quadrante_1, quadrante_2, quadrante_3, quadrante_4):
    imagem_temp = quadrante_1.copy()
    quadrante_1[:] = quadrante_3
    quadrante_3[:] = imagem_temp

    imagem_temp = quadrante_2.copy()
    quadrante_2[:] = quadrante_4
    quadrante_4[:] = imagem_temp

    imagem_resultante = cv2.vconcat([cv2.hconcat([quadrante_2, quadrante_1]), cv2.hconcat([quadrante_4, quadrante_3])])

    return imagem_resultante

def salvar_imagem(nome_arquivo, imagem):
    cv2.imwrite(nome_arquivo, imagem)

def exibir_imagem(imagem, nome_janela="Imagem Final"):
    cv2.imshow(nome_janela, imagem)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

def main():
    nome_arquivo = "fib.png"
    imagem = carregar_imagem(nome_arquivo)
    quadrante_1, quadrante_2, quadrante_3, quadrante_4 = dividir_quadrantes(imagem)
    imagems = trocar_quadrantes(quadrante_1, quadrante_2, quadrante_3, quadrante_4)
    salvar_imagem("q3.png", quadrante_2)
    salvar_imagem("q4.png", quadrante_1)
    salvar_imagem("q1.png", quadrante_3)
    salvar_imagem("q2.png", quadrante_4)
    salvar_imagem("regioes-trocadas.png", imagems)
    exibir_imagem(imagems)

if __name__ == "__main__":
    main()</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resultado_2">Resultado</h4>
<div class="imageblock">
<div class="content">
<img src="images/f.png" alt="f">
</div>
<div class="title">Figure 2. Regiões trocadas</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_3_serialização_de_dados_em_ponto_flutuante_via_filestorage">3. Serialização de dados em ponto flutuante via FileStorage</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_3_1_exercício">3.1 Exercício</h3>
<div class="paragraph">
<p>Utilizando o programa-exemplo filestorage.cpp como base, crie um programa que gere uma imagem de dimensões 256x256 pixels contendo uma senóide de 4 períodos com amplitude igual 127 desenhada na horizontal, semelhante àquela apresentada na Figura 6. Grave a imagem no formato YML e também exporte no formato PNG, como faz o programa-exemplo. Compare os arquivos gerados, extraindo uma linha correspondente de cada imagem gravada e comparando a diferença entre elas. Trace um gráfico da diferença calculada ao longo da linha correspondente extraída nas imagens. O que você observa? Por que isso acontece?</p>
</div>
<div class="sect3">
<h4 id="_solução_3">Solução</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Criação da senoide:</p>
<div class="ulist">
<ul>
<li>
<p>Cria uma matriz de zeros com dimensão (256x256px).</p>
</li>
<li>
<p>Para cada pixel na imagem, calcula o valor da senoide e atribui à matriz.</p>
</li>
<li>
<p>O cálculo é baseado na fórmula da função senoide: sen(x) = 127*sin(2*pi*Tx/l)+128.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Salva a matriz da imagem em uma arquivo YML.</p>
</li>
<li>
<p>Normalização da imagem:</p>
<div class="ulist">
<ul>
<li>
<p>Normaliza a imagem para o intervalo de 0 a 255.</p>
</li>
<li>
<p>Converte a imagem normalizada para o tipo de dados uint8.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Salva a imagem normalizada em formato PNG.</p>
</li>
<li>
<p>Exibe a imagem gerada.</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2
import numpy as np
import math

# Dimensão da imagem (256x256px)
LADO = 256
# Número de períodos da senoide
PERIODOS = 4

# Criar uma matriz de zeros para a imagem
imagem = np.zeros((LADO, LADO), dtype=np.float32)

for linha in range(LADO):
    for coluna in range(LADO):
        imagem[linha, coluna] = 127 * math.sin(2 * math.pi * PERIODOS * coluna / LADO) + 128

# Salvar a imagem em formato YML
ss_yml = f"senoide-{LADO}.yml"
fs = cv2.FileStorage(ss_yml, cv2.FILE_STORAGE_WRITE)
fs.write("matriz", imagem)
fs.release()

# Normalização da imagem
imagem_normalizada = cv2.normalize(imagem, None, 0, 255, cv2.NORM_MINMAX)

imagem_normalizada_uint8 = imagem_normalizada.astype(np.uint8)

# Salvar a imagem em formato PNG
ss_png = f"senoide-{LADO}.png"
cv2.imwrite(ss_png, imagem_normalizada_uint8)

# Exibir a imagem
cv2.imshow("Senoide", imagem_normalizada_uint8)
cv2.waitKey(0)
cv2.destroyAllWindows()</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resultado_3">Resultado</h4>
<div class="imageblock">
<div class="content">
<img src="images/senoide-256.png" alt="senoide 256">
</div>
<div class="title">Figure 3. Senoide</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_4_decomposição_de_imagens_digitais">4. Decomposição de imagens digitais</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_4_1_esteganografia">4.1 Esteganografia</h3>

</div>
<div class="sect2">
<h3 id="_4_2_exercicio">4.2 Exercicio</h3>
<div class="paragraph">
<p>Usando o programa bitplanes.cpp como referência para esteganografia, escreva um programa que recupere a imagem codificada de uma imagem resultante de esteganografia. Lembre-se que os bits menos significativos dos pixels da imagem fornecida deverão compor os bits mais significativos dos pixels da imagem recuperada. O programa deve receber como parâmetros de linha de comando o nome da imagem resultante da esteganografia. Teste a sua implementação com a imagem da Figura 13 (desafio-esteganografia.png).</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/este.png" alt="este">
</div>
<div class="title">Figure 4. Imagem Codificada</div>
</div>
<div class="sect3">
<h4 id="_solução_4">Solução</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Recuperação da Imagem:</p>
<div class="ulist">
<ul>
<li>
<p>Verifica se o nome do arquivo de imagem foi fornecido como argumento de linha de comando.</p>
</li>
<li>
<p>Carrega a imagem resultante da esteganografia.</p>
</li>
<li>
<p>Cria uma matriz de zeros para imagem recuperada.</p>
</li>
<li>
<p>Para cada pixel na imagem resultante, recupera o valor original dos bits menos significativos.</p>
</li>
<li>
<p>Salva a imagem recuperada em um arquivo PNG.</p>
</li>
<li>
<p>Exibe a imagem recuperada.</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2
import numpy as np
import sys

# Número de bits menos significativos usados na esteganografia
BITS_LSB = 3

def recuperar_imagem():
    # Verificar se o nome do arquivo de imagem foi fornecido como argumento de linha de comando
    if len(sys.argv) &lt; 2:
        sys.exit(1)

    # Carregar a imagem resultante da esteganografia
    imagem_resultante = cv2.imread(sys.argv[1], cv2.IMREAD_COLOR)

    if imagem_resultante is None:
        print("Não foi possível carregar a imagem resultante da esteganografia.")
        sys.exit(1)

    # Criar uma matriz de zeros para a imagem recuperada
    imagem_recuperada = np.zeros_like(imagem_resultante)

    for linha in range(imagem_resultante.shape[0]):
        for coluna in range(imagem_resultante.shape[1]):
            valor_resultante = imagem_resultante[linha, coluna]
            valor_recuperado = np.zeros(3, dtype=np.uint8)

            for canal in range(3):
                valor_recuperado[canal] = valor_resultante[canal] &lt;&lt; (8 - BITS_LSB) &amp; 0xFF

            imagem_recuperada[linha, coluna] = valor_recuperado

    # Nome do arquivo para salvar a imagem recuperada
    nome_arquivo = 'imagem_final.png'

    # Salvar a imagem recuperada
    cv2.imwrite(nome_arquivo, imagem_recuperada)

    # Exibir a imagem recuperada
    cv2.imshow("Imagem Final", imagem_recuperada)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

recuperar_imagem()</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resultado_4">Resultado</h4>
<div class="imageblock">
<div class="content">
<img src="images/imagem_final.png" alt="imagem final">
</div>
<div class="title">Figure 5. Imagem Recuperada</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_5_preenchendo_regiões">5. Preenchendo regiões</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_5_1_exercicio">5.1 Exercicio</h3>
<div class="paragraph">
<p>Observando-se o programa labeling.cpp como exemplo, é possível verificar que caso existam mais de 255 objetos na cena, o processo de rotulação poderá ficar comprometido, visto que o tipo de dado usado para suportar imagens cinzentas permitem armazenar apenas um byte por pixel. Identifique a situação em que isso ocorre e proponha uma solução para este problema.</p>
</div>
<div class="sect3">
<h4 id="_solução_5">Solução</h4>
<div class="paragraph">
<p>Para resolver o problema dos casos em que a imagem contenha mais de 255 objetos a serem rotulados, podemos usar uma estratégia de atribuir rótulos em ponto flutuante ou rotular usando a operação módulo de 255.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_5_2_exercicio">5.2 exercicio</h3>
<div class="paragraph">
<p>Aprimore o algoritmo de contagem apresentado para identificar regiões com ou sem buracos internos que existam na cena. Assuma que objetos com mais de um buraco podem existir. Inclua suporte no seu algoritmo para não contar bolhas que tocam as bordas da imagem. Não se pode presumir, a priori, que elas tenham buracos ou não.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/bolhas.png" alt="bolhas">
</div>
<div class="title">Figure 6. Bolhas original</div>
</div>
<div class="sect3">
<h4 id="_solução_6">Solução</h4>
<div class="paragraph">
<p>O código realiza a contagem de bolhas na imagem:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>A imagem é carregada em escala de cinza. Se a imagem não for carregada corretamente, uma mensagem de erro é exibida e o programa é encerrado.</p>
</li>
<li>
<p>Exclusão das Bordas:</p>
<div class="ulist">
<ul>
<li>
<p>As bordas brancas da imagem são removidas usando o algoritmo de preenchimento de região (flood fill).</p>
</li>
</ul>
</div>
</li>
<li>
<p>Os objetos na imagem são contados e preenchidos com um valor de intensidade único usando o flood fill.</p>
</li>
<li>
<p>As bolhas com buracos são contadas e preenchidas com um valor diferente de cor.</p>
</li>
<li>
<p>A imagem resultante, com as bolhas sem lacunas e a contagem são exibidas.</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2

image = cv2.imread("bolhas.png", cv2.IMREAD_GRAYSCALE)

if image is None:
  print("Imagem não carregou corretamente")
  exit()

# Obtendo largura e altura da imagem
width = image.shape[1]
height = image.shape[0]

# Excluir bordas
for i in range(height):
  if image[0,i] == 255:
    cv2.floodFill(image, None, (i,0), 0)
  if image[width - 1, i] == 255:
    cv2.floodFill(image, None, (i, width - 1), 0)

for i in range(width):
  if image[i,0] == 255:
    cv2.floodFill(image, None, (0,i), 0)
  if image[i, height - 1] == 255:
    cv2.floodFill(image, None, (height - 1, i),0)

# Visualizar imagem sem bordas
cv2.imshow("Imagem_sembordas.png", image)
cv2.imwrite("Imagem_sembordas.png", image)

# Inicializando contagem de objetos
nobjects = 0

# Procurar objetos na imagem
for i in range(height):
  for j in range(width):
    if image[i,j] == 255:
      nobjects += 1
      seed_point = (j,i)
      cv2.floodFill(image, None, seed_point, nobjects)

# preenche o fundo de branco para contagem de buracos
cv2.floodFill(image, None, (0,0), 255)

counte = 0
for i in range(height):
     for j in range(width):
      if image[i, j] == 0 and image[i, j - 1] &gt; counte:
        counte += 1
        cv2.floodFill(image, None, (j - 1, i), counte)

cv2.imshow("Imagen-cont", image )

counter = 0
for i in range(height):
  for j in range(width):
    if image[i, j] == 0:
      cv2.floodFill(image, None, (j, i-1), 255)

print(f"A figura tem : \n{nobjects - counte} bolhas\n{counte} bolhas com buracos\nTotal: {nobjects} bolhas")

# Exibir a imagem com a segmentação
cv2.imshow("imagem", image)
cv2.imwrite("labeling.png", image)
cv2.waitKey(0)
cv2.destroyAllWindows()</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resultado_5">Resultado</h4>
<div class="imageblock">
<div class="content">
<img src="images/imagem_sembordas.png" alt="imagem sembordas">
</div>
<div class="title">Figure 7. Imagem sem bordas</div>
</div>
<div class="imageblock">
<div class="content">
<img src="images/labeling.png" alt="labeling">
</div>
<div class="title">Figure 8. resultado</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">A figura tem :
14 bolhas
7 bolhas com buracos
Total: 21 bolhas</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_6_manipulando_histogramas">6 Manipulando histogramas</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_6_1_equalização">6.1 Equalização</h3>
<div class="paragraph">
<p>Utilizando o programa exemplos/histogram.cpp como referência, implemente um programa equalize.cpp. Este deverá, para cada imagem capturada, realizar a equalização do histogram antes de exibir a imagem. Teste sua implementação apontando a câmera para ambientes com iluminações variadas e observando o efeito gerado. Assuma que as imagens processadas serão em tons de cinza.</p>
</div>
<div class="sect3">
<h4 id="_solução_7">Solução</h4>
<div class="paragraph">
<p>A resolução consistiu nas seguintes etapas:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Captura de Vídeo:</p>
<div class="ulist">
<ul>
<li>
<p>Inicializa a câmera para captura de vídeo.</p>
</li>
<li>
<p>Se nenhuma câmera estiver disponível, exibe uma mensagem de erro e encerra o programa.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Processamento de Vídeo:</p>
<div class="ulist">
<ul>
<li>
<p>Para cada frame capturado, o progama:</p>
</li>
<li>
<p>Converte o frame para escala de cinza.</p>
</li>
<li>
<p>Equaliza o histograma do frame em escala de cinza.</p>
</li>
<li>
<p>Exibe o frame original e o frame equalizado em janelas separadas.</p>
</li>
<li>
<p>Salva os frames "orignal" e "equalizado" como imagens PNG.</p>
</li>
</ul>
</div>
</li>
<li>
<p>O programa é encerrado com o "Esc"</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2

def main():
    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        print("Câmeras indisponíveis")
        return

    while True:
        ret, frame = cap.read()

        if not ret:
            break

        grayscale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        equalized = cv2.equalizeHist(grayscale)

        cv2.namedWindow("normal", cv2.WINDOW_NORMAL)
        cv2.namedWindow("equalizada", cv2.WINDOW_NORMAL)

        cv2.imshow("normal", grayscale)
        cv2.imshow("equalizada", equalized)

        cv2.imwrite("frame_normal.png", grayscale)
        cv2.imwrite("frame_equalizada.png", equalized)

        key = cv2.waitKey(30)
        if key == 27:
            break

    cv2.destroyAllWindows()
    cap.release()

if __name__ == "__main__":
    main()</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resultados">Resultados</h4>
<div class="imageblock">
<div class="content">
<img src="images/ser.gif" alt="ser">
</div>
<div class="title">Figure 9. Equalização</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_6_2_detecção_de_movimento">6.2 Detecção de Movimento</h3>
<div class="paragraph">
<p>Utilizando o programa exemplos/histogram.cpp como referência, implemente um programa motiondetector.cpp. Este deverá continuamente calcular o histograma da imagem (apenas uma componente de cor é suficiente) e compará-lo com o último histograma calculado. Quando a diferença entre estes ultrapassar um limiar pré-estabelecido, ative um alarme. Utilize uma função de comparação que julgar conveniente.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2

def histograma(imagem, bins):
    hist = cv2.calcHist([imagem], [0], None, [bins], [0, 256])
    return hist

# def main():
cap = cv2.VideoCapture(0)

if not cap.isOpened():
   print("Câmeras indisponíveis")


ret, imagem = cap.read()
hist_novo = histograma(imagem, 256)
hist_anterior = hist_novo.copy()
temp = 0

while True:
  ret, imagem = cap.read()
  imagem_gray = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)
  hist_novo = histograma(imagem_gray, 256)

  compara = cv2.compareHist(hist_novo, hist_anterior, cv2.HISTCMP_CORREL)

  if compara &lt;= 0.93:  # Altere o valor de comparação conforme necessário
    print("Movimento detectado - Ordem:", temp)
    temp += 1

  cv2.imshow("Detector de Movimento", imagem)

  if cv2.waitKey(1) &amp; 0xFF == ord('q'):  # Pressione 'q' para sair
    break

  hist_anterior = hist_novo.copy()

cap.release()
cv2.destroyAllWindows()</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="_resultados_2">Resultados</h4>
<div class="imageblock">
<div class="content">
<img src="images/detect.gif" alt="detect">
</div>
<div class="title">Figure 10. Detecção de movimentos</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_7_filtragem_no_dominio_espacial_i">7 Filtragem no dominio espacial I</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_7_1_exercício">7.1 Exercício</h3>
<div class="paragraph">
<p>Utilizando o programa exemplos/convolucao.cpp como referência, implemente um programa laplgauss.cpp. O programa deverá acrescentar mais uma funcionalidade ao exemplo fornecido, permitindo que seja calculado o laplaciano do gaussiano das imagens capturadas. Compare o resultado desse filtro com a simples aplicação do filtro laplaciano.</p>
</div>
<div class="sect3">
<h4 id="_solução_8">Solução</h4>
<div class="paragraph">
<p>Para a resolução desse exercício foi apenas necessário adicionar a máscara do laplaciano do gaussiano junto com as demais máscaras já implementadas do código original e colocar a opção de escolher a nova máscara digitando a tecla "p". Ao comparar o filtro laplaciano com o laplaciano do gaussiano percebe-se uma acentuação dos contornos e também existem mais contornos visíveis, como pode ser visto em <code>Resultados</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2
import numpy as np

def printmask(m):
    for i in range(m.shape[0]):
        for j in range(m.shape[1]):
            print(m[i, j], end=",")
        print()

def main():
    cap = cv2.VideoCapture(1)
    media = np.array([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111], dtype=np.float32)
    gauss = np.array([0.0625, 0.125, 0.0625, 0.125, 0.25, 0.125, 0.0625, 0.125, 0.0625], dtype=np.float32)
    horizontal = np.array([-1, 0, 1, -2, 0, 2, -1, 0, 1], dtype=np.float32)
    vertical = np.array([-1, -2, -1, 0, 0, 0, 1, 2, 1], dtype=np.float32)
    laplacian = np.array([0, -1, 0, -1, 4, -1, 0, -1, 0], dtype=np.float32)
    boost = np.array([0, -1, 0, -1, 5.2, -1, 0, -1, 0], dtype=np.float32)
    laplgauss = np.array([0, 0, -1, 0, 0, 0, -1, -2, -1, 0, -1, -2, 16, -2, -1, 0, -1, -2, -1, 0, 0, 0, -1, 0, 0], dtype=np.float32)

    if not cap.isOpened():
        print("Câmeras indisponíveis")
        return -1

    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
    print("largura =", width)
    print("altura =", height)
    print("fps =", cap.get(cv2.CAP_PROP_FPS))
    print("formato =", cap.get(cv2.CAP_PROP_FORMAT))

    cv2.namedWindow("filtroespacial", cv2.WINDOW_NORMAL)
    cv2.namedWindow("original", cv2.WINDOW_NORMAL)

    mask = np.zeros((3, 3), dtype=np.float32)
    absolut = 1

    while True:
        ret, frame = cap.read()
        framegray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        framegray = cv2.flip(framegray, 1)
        cv2.imshow("original", framegray)

        frame32f = framegray.astype(np.float32)
        frameFiltered = cv2.filter2D(frame32f, -1, mask, anchor=(1, 1), delta=0)

        if absolut:
            frameFiltered = np.abs(frameFiltered)

        result = frameFiltered.astype(np.uint8)

        cv2.imshow("filtroespacial", result)

        key = cv2.waitKey(10)
        if key == 27:
            break  # Esc pressed!
        elif key == ord('a'):
            absolut = not absolut
        elif key == ord('m'):
            mask = np.reshape(media, (3, 3))
            printmask(mask)
        elif key == ord('g'):
            mask = np.reshape(gauss, (3, 3))
            printmask(mask)
        elif key == ord('h'):
            mask = np.reshape(horizontal, (3, 3))
            printmask(mask)
        elif key == ord('v'):
            mask = np.reshape(vertical, (3, 3))
            printmask(mask)
        elif key == ord('l'):
            mask = np.reshape(laplacian, (3, 3))
            printmask(mask)
        elif key == ord('p'):
            mask = np.reshape(laplgauss, (5, 5))
            printmask(mask)
        elif key == ord('b'):
            mask = np.reshape(boost, (3, 3))

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resultados_3">Resultados</h4>
<div class="imageblock">
<div class="content">
<img src="images/comp.gif" alt="comp">
</div>
<div class="title">Figure 11. Comparação</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_8_filtragem_no_dominio_espacial_ii">8 Filtragem no dominio espacial II</h2>
<div class="sectionbody">

</div>
</div>
<div class="sect1">
<h2 id="_9_a_tranformada_discreta_de_fourier">9 A Tranformada Discreta de Fourier</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_exercicio_9_1">Exercicio 9.1</h3>
<div class="paragraph">
<p>Utilizando os programa exemplos/dft.cpp, calcule e apresente o espectro de magnitude da imagem Figura 40, “Imagem senoidal com 256x256 pixels”.Compare o espectro de magnitude gerado para a figura Figura 40, “Imagem senoidal com 256x256 pixels” com o valor teórico da transformada de Fourier da senóide.</p>
</div>
<div class="sect3">
<h4 id="_solução_9">Solução</h4>
<div class="paragraph">
<p>O resultado do espectro de magnitude gerado pelo código representa a magnitude da transformada de Fourier da imagem, mas essa não é idêntica ao valor teórico da transformada de Fourier de uma senoide pura, visto que, para o funcionamento do código, foram realizadas alterações no valor do log e, consequentemente, houve uma modificação na distribuição de valores do espectro. Além disso, a diferença é esperada devido às características específicas da imagem processada e às transformações aplicadas durante o cálculo e exibição do espectro</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2
import numpy as np
import matplotlib.pyplot as plt

def swap_quadrants(image):
  image = image[:image.shape[0] &amp; -2, :image.shape[1] &amp; -2]

  centerX = image.shape[1] // 2
  centerY = image.shape[0] // 2

  A = image[:centerY, :centerX]
  B = image[:centerY, centerX:]
  C = image[centerY:, :centerX]
  D = image[centerY:, centerX:]

  tmp = A.copy()
  A[:] = D
  D[:] = tmp

  tmp = B.copy()
  B[:] = C
  C[:] = tmp

def calculate_magnitude_spectrum(image):
  dft_M = cv2.getOptimalDFTSize(image.shape[0])
  dft_N = cv2.getOptimalDFTSize(image.shape[1])
  padded = cv2.copyMakeBorder(image,0,dft_M - image.shape[0], 0, dft_N - image.shape[1], cv2.BORDER_CONSTANT, value=0)

  complex_image = cv2.dft(np.float32(padded), flags=cv2.DFT_COMPLEX_OUTPUT)
  swap_quadrants(complex_image)

  magnitude = cv2.magnitude(complex_image[:,:,0], complex_image[:,:,1])
  magnitude +=1
  magnitude = np.log(magnitude)
  magnitude = cv2.normalize(magnitude, None, 0, 1, cv2.NORM_MINMAX)

  return magnitude

image = cv2.imread("senoide-256.png", cv2.IMREAD_GRAYSCALE)

magnitude_spectrum = calculate_magnitude_spectrum(image)

plt.subplot(121), plt.imshow(image, cmap = 'gray')
plt.title("image"), plt.axis("off")
plt.subplot(122), plt.imshow(magnitude_spectrum, cmap='gray')
plt.title("Magnitude spectrum"), plt.axis('off')
plt.show()</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resultados_4">Resultados</h4>
<div class="imageblock">
<div class="content">
<img src="exercicios/fourier-t/spectrum-senoide.png" alt="spectrum senoide">
</div>
<div class="title">Figure 12. original senoide</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_exercicio_9_2">Exercicio 9.2</h3>
<div class="paragraph">
<p>Usando agora o filestorage.cpp, mostrado na Listagem 15, “filestorage.cpp” como referência, adapte o programa exemplos/dft.cpp para ler a imagem em ponto flutuante armazenada no arquivo YAML equivalente (ilustrado na Listagem 18, “trecho do arquivo senoide-256.yml”).</p>
</div>
<div class="sect3">
<h4 id="_solução_10">Solução</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2
import numpy as np
import matplotlib.pyplot as plt

def swap_quadrants(image):
    tmp = np.copy(image)
    cx = image.shape[1] // 2
    cy = image.shape[0] // 2
    image[:cy, :cx] = tmp[cy:, cx:]
    image[cy:, cx:] = tmp[:cy, :cx]
    image[:cy, cx:] = tmp[cy:, :cx]
    image[cy:, :cx] = tmp[:cy, cx:]

def main():
    # Carrega a imagem em ponto flutuante a partir do arquivo YAML
    fs = cv2.FileStorage("senoide-256.yml", cv2.FILE_STORAGE_READ)
    image = fs.getNode("mat").mat()
    fs.release()

    # Calcula a transformada de Fourier
    complex_image = cv2.dft(image, flags=cv2.DFT_COMPLEX_OUTPUT)
    swap_quadrants(complex_image)

    # Separa os planos real e imaginário
    planes = cv2.split(complex_image)

    # Calcula o espectro de magnitude
    magnitude = cv2.magnitude(planes[0], planes[1])
    magnitude += 1
    cv2.log(magnitude, magnitude)

    # Normaliza a magnitude
    cv2.normalize(magnitude, magnitude, 0, 1, cv2.NORM_MINMAX)

    # Exibe as imagens processadas
    cv2.imshow("Imagem", image.astype(np.uint8))
    cv2.imshow("Espectro de magnitude", magnitude)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resultados_5">Resultados</h4>
<div class="imageblock">
<div class="content">
<img src="exercicios/fourier-t/update-spectrum.png" alt="update spectrum">
</div>
<div class="title">Figure 13. original senoide</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_exercicio_9_3">Exercicio 9.3</h3>
<div class="paragraph">
<p>Compare o novo espectro de magnitude gerado com o valor teórico da transformada de Fourier da senóide. O que mudou para que o espectro de magnitude gerado agora esteja mais próximo do valor teórico? Porque isso aconteceu?</p>
</div>
<div class="sect3">
<h4 id="_solução_11">Solução</h4>
<div class="paragraph">
<p>No código C++ original, o espectro de magnitude é calculado usando a função <code>cv::magnitude(planos[0], planos[1], magn)</code>, que retorna a magnitude complexa direta sem adicionar 1 ou calcular o logaritmo. No código Python adaptado, adicionamos 1 ao espectro de magnitude e aplicamos o logaritmo antes de normalizar.</p>
</div>
<div class="paragraph">
<p>Essas alterações evitam o logaritmo de zero e comprimem a faixa dinâmica dos valores para melhorar a visualização, mas modificam a escala e a distribuição dos valores do espectro, resultando em diferenças visuais significativas em relação ao valor teórico.</p>
</div>
<div class="paragraph">
<p>Para um resultado mais próximo do valor teórico, remova a adição de 1 e o logaritmo do cálculo do espectro de magnitude no código Python. O espectro de magnitude gerado será mais semelhante ao valor teórico da transformada de Fourier da senoide.</p>
</div>
<div class="paragraph">
<p>Vale lembrar que o espectro de magnitude gerado representa a magnitude da transformada de Fourier da imagem, mas não é idêntico ao valor teórico da transformada de Fourier de uma senoide pura, devido às características específicas da imagem processada e às transformações aplicadas.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_10_filtragem_no_domínio_da_frequência">10 Filtragem no Domínio da Frequência</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_exercicio">Exercicio</h3>
<div class="paragraph">
<p>Utilizando o programa exemplos/dftfilter.cpp como referência, implemente o filtro homomórfico para melhorar imagens com iluminação irregular. Crie uma cena mal iluminada e ajuste os parâmetros do filtro homomórfico para corrigir a iluminação da melhor forma possível. Assuma que a imagem fornecida é em tons de cinza.</p>
</div>
<div class="sect3">
<h4 id="_solução_12">Solução</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Função shift_dft: Reorganiza o espectro de magnitude para centralizar a componente de baixa frequência.</p>
</li>
<li>
<p>Função define_homomorphic_filter: Define um filtro homomórfico baseado nos parâmetros fornecidos (frequência de corte, constantes, etc.).</p>
</li>
<li>
<p>Função show_images: Exibe a imagem original e a imagem filtrada em janelas separadas.</p>
</li>
<li>
<p>Função options: Ajusta os parâmetros do filtro homomórfico com base nas teclas pressionadas pelo usuário.</p>
</li>
<li>
<p>Função main:</p>
<div class="ulist">
<ul>
<li>
<p>Carrega a imagem original e redimensiona.</p>
</li>
<li>
<p>Calcula o tamanho ideal para a DFT.</p>
</li>
<li>
<p>Adiciona bordas à imagem para ajustar ao tamanho ideal.</p>
</li>
<li>
<p>Define os parâmetros iniciais do filtro homomórfico.</p>
</li>
<li>
<p>Aplica o filtro homomórfico iterativamente, permitindo ajustes interativos dos parâmetros.</p>
</li>
<li>
<p>Exibe a imagem original e a filtrada.</p>
</li>
<li>
<p>Atualiza os parâmetros do filtro com base na entrada do usuário.</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>O filtro homomórfico é usado para realçar características da imagem, e o código permite ajustes interativos dos parâmetros para observar os efeitos em tempo real.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-pyhton hljs" data-lang="pyhton">import cv2
import numpy as np
import sys

def shift_dft(image):
  rows, cols = image.shape[:2]

  regions = [
    image[rows // 2: rows, cols // 2:cols],
    image[rows // 2:rows, 0:cols // 2],
    image[0:rows // 2, cols // 2:cols],
    image[0:rows // 2, 0:cols // 2]]

  a = np.hstack(regions[0:2])
  b = np.hstack(regions[2:4])

  return np.vstack((a,b))

def define_homomorphic_filter(rows, cols, d_0, c, gamma_high, gamma_low):
  homomorphic = np.zeros((rows, cols))

  rows_half = rows // 2
  cols_half = cols // 2

  for i in range(rows):
    i_diff = i - rows_half
    i_diff_square = i_diff * i_diff

    for j in range(cols):
      j_diff = j - cols_half
      j_diff_square = j_diff * j_diff

      d_2 = i_diff_square + j_diff_square
      exp_value = np.exp(-c*d_2/(d_0**2))
      homomorphic[i,j] = (gamma_high - gamma_low) * (1-exp_value) + gamma_low

  return cv2.merge([homomorphic, homomorphic])

def show_images(window_names, images, time):
  for image, window_name in zip(images, window_names):
    cv2.imshow(window_name, image)

  return chr(cv2.waitKey(time) &amp; 255)

def options(key, c, gamma_high, gamma_low, d0):
  if key == "C":
    c += 0.5
  elif key == "c":
    c -= 0.5
    if c &lt; 0:
      c =0
  elif key == "G":
    gamma_low += 0.5
  elif key == "g":
    gamma_low -= 0.5
    if gamma_low &lt; gamma_low + 1:
      gamma_low = gamma_low + 1
  elif key == "D":
    d0 += 0.5
  elif key == "d":
    d0 -= 0.5

  return c, gamma_high, gamma_low, d0

def main():
  original_image = cv2.imread(sys.argv[1], cv2.IMREAD_GRAYSCALE)
  original_image = cv2.resize(original_image, (1280, 720))

  dft_rows = cv2.getOptimalDFTSize(original_image.shape[0])
  dft_cols = cv2.getOptimalDFTSize(original_image.shape[1])

  padded_rows = dft_rows - original_image.shape[0]
  padde_cols = dft_cols - original_image.shape[1]

  original_window_name = "original image"
  filtered_window_name = "homomophirc filter"

  c = 1
  gamma_high = 2
  gamma_low = 0.5
  d0 = 4.5

  homomorphic = define_homomorphic_filter(dft_rows, dft_cols, d0, c, gamma_high, gamma_low)

  padded = cv2.copyMakeBorder(original_image, 0, padded_rows, 0, padde_cols, cv2.BORDER_CONSTANT, value=[0,0,0])

  key = "não"

  while "\x1b" != key:
    planes = np.log(padded.astype(np.float64)+1)
    planes = cv2.merge([planes, np.zeros(padded.shape, np.float64)])

    dft_image = cv2.dft(planes, flags=cv2.DFT_COMPLEX_OUTPUT)

    shifted_image = shift_dft(dft_image)

    filtered_image = cv2.mulSpectrums(shifted_image, homomorphic, 0)

    dft_image = shift_dft(filtered_image)

    image = cv2.idft(dft_image, flags=cv2.DFT_SCALE | cv2.DFT_REAL_OUTPUT)

    cv2.normalize(image, image, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_64F)

    key = show_images([original_window_name, filtered_window_name], [original_image, image], 0)

    c, gamma_high, gamma_low, d0 = options(key, c, gamma_high, gamma_low, d0)

    print("c {}, gamma high {}, gamma low {}, d0 {}".format(c, gamma_high, gamma_low, d0))

    homomorphic = define_homomorphic_filter(dft_rows, dft_cols, d0, c, gamma_high, gamma_low)

if __name__ == '__main__':
  main()</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resultados_6">Resultados</h4>
<div class="imageblock">
<div class="content">
<img src="exercicios/homomorphic-filter/frame-update.png" alt="frame update">
</div>
<div class="title">Figure 14. Filtro Homomórfico</div>
</div>
<div class="imageblock">
<div class="content">
<img src="exercicios/homomorphic-filter/frame.png" alt="frame">
</div>
<div class="title">Figure 15. Sem Filtro</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_11_detecção_de_bordas_com_o_algoritmo_canny">11 Detecção de bordas com o algoritmo Canny</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_exercicio_2">Exercicio</h3>
<div class="paragraph">
<p>Utilizando os programas exemplos/canny.cpp e exemplos/pontilhismo.cpp como referência, implemente um programa cannypoints.cpp. A idéia é usar as bordas produzidas pelo algoritmo de Canny para melhorar a qualidade da imagem pontilhista gerada. A forma como a informação de borda será usada é livre. Entretanto, são apresentadas algumas sugestões de técnicas que poderiam ser utilizadas:</p>
</div>
<div class="paragraph">
<p>Desenhar pontos grandes na imagem pontilhista básica;
Usar a posição dos pixels de borda encontrados pelo algoritmo de Canny para desenhar pontos nos respectivos locais na imagem gerada.
Experimente ir aumentando os limiares do algoritmo de Canny e, para cada novo par de limiares, desenhar círculos cada vez menores nas posições encontradas. A Figura 48, “Pontilhismo aplicado à imagem Lena” foi desenvolvida usando essa técnica.</p>
</div>
<div class="sect3">
<h4 id="_solução_13">Solução</h4>
<div class="paragraph">
<p>Para resolver este exercício, adaptei o código do pontilhismo aplicando o algoritmo de Canny à imagem em questão. Após isso, um laço for aninhado preserva a posição e a cor original. Em seguida, desenhamos pequenos círculos nos pontos obtidos das bordas detectadas pelo Canny, resultando na imagem final. A seguir, apresento o código e os resultados:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2
import numpy as np
import random
import requests
from io import BytesIO

# Constantes
STEP = 6
JITTER = 4
RAIO = 6
RAIO_PEQUENO = 3
IMAGE_URL = 'https://img.freepik.com/free-photo/futuristic-exploration-dubai-s-evolving-cityscape_23-2151339724.jpg?t=st=1719255845~exp=1719259445~hmac=5c6f5d7a28bc9bab8cf242a871d83a144ea92a9dc0f554221a554ffa78352225&amp;w=1060'

def download_image(url):
    response = requests.get(url)
    response.raise_for_status()
    image_data = response.content
    return cv2.imdecode(np.array(bytearray(image_data), dtype=np.uint8), cv2.IMREAD_COLOR)

def apply_canny_edge_detection(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    return cv2.Canny(gray, 80, 240)

def generate_pointillism(image, edge_image):
    height, width, _ = image.shape
    points = np.full((height, width, 3), (255, 255, 255), dtype=np.uint8)
    xrange = list(range(0, height, STEP))
    yrange = list(range(0, width, STEP))

    random.shuffle(xrange)
    random.shuffle(yrange)

    # Amostragem aleatória de pontos
    for i in xrange:
        for j in yrange:
            x = i + random.randint(-JITTER, JITTER)
            y = j + random.randint(-JITTER, JITTER)
            x = min(max(x, 0), height - 1)
            y = min(max(y, 0), width - 1)
            color = tuple(map(int, image[x, y]))
            cv2.circle(points, (y, x), RAIO, color, -1, cv2.LINE_AA)

    # Adiciona pontos baseados nas bordas
    border_points = []
    for i in range(height):
        for j in range(width):
            if edge_image[i, j] != 0:
                color = tuple(map(int, image[i, j]))
                border_points.append([j, i, color[0], color[1], color[2]])

    random.shuffle(border_points)

    for ponto in border_points:
        x, y, b, g, r = ponto
        color = (b, g, r)
        cv2.circle(points, (x, y), RAIO_PEQUENO, color, -1, cv2.LINE_AA)

    return points

def main():
    image = download_image(IMAGE_URL)

    cv2.imshow("Imagem Original", image)
    cv2.waitKey(0)

    edge_image = apply_canny_edge_detection(image)
    cv2.imshow("Bordas Canny", edge_image)
    cv2.waitKey(0)

    pointillism_image = generate_pointillism(image, edge_image)
    cv2.imshow("Imagem Pontilhista", pointillism_image)
    cv2.waitKey(0)

    cv2.imwrite("cannypoints.png", pointillism_image)
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resultados_7">Resultados</h4>
<div class="imageblock">
<div class="content">
<img src="exercicios/canny/cannypoints.png" alt="cannypoints">
</div>
<div class="title">Figure 16. Equalização</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_12_quantização_vetorial_com_k_means">12 Quantização vetorial com K-means</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_exercicio_3">Exercicio</h3>
<div class="paragraph">
<p>Utilizando o programa kmeans.cpp como exemplo prepare um programa exemplo onde a execução do código se dê usando o parâmetro nRodadas=1 e inciar os centros de forma aleatória usando o parâmetro KMEANS_RANDOM_CENTERS ao invés de KMEANS_PP_CENTERS. Realize 10 rodadas diferentes do algoritmo e compare as imagens produzidas. Explique porque elas podem diferir tanto.</p>
</div>
<div class="sect3">
<h4 id="_solução_14">Solução</h4>
<div class="paragraph">
<p>A solução é dada da seguinte forma: a matriz <code>samples</code> deve conter em cada linha uma das amostras a serem processadas pela função <code>nClusters</code>, que informa a quantidade de aglomerados que se deseja obter, no nosso caso, 8. A matriz <code>rotulos</code> é um objeto do tipo <code>Mat</code> preenchido com elementos do tipo <code>int</code>, onde cada elemento identifica a classe à qual pertence a amostra na matriz <code>samples</code>. Aqui, realizamos no máximo 10.000 iterações ou utilizamos uma tolerância de 0.0001 para finalizar o algoritmo. O algoritmo é repetido por uma quantidade de vezes definida por <code>nRodadas</code>, sendo escolhida como vencedora a rodada que produz a menor soma de distâncias dos pontos para seus respectivos centros. Foi utilizada a inicialização dos centros de forma aleatória com <code>KMEANS_RANDOM_CENTERS</code>, como veremos a seguir:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2
import numpy as np
import requests

def download_image(url):
    response = requests.get(url)
    if response.status_code == 200:
        return cv2.imdecode(np.frombuffer(response.content, np.uint8), cv2.IMREAD_COLOR)
    else:
        raise Exception("Erro ao baixar a imagem")

def kmeans_clustering(image, n_clusters=8, n_iterations=10, n_rodadas=1):
    samples = np.float32(image.reshape(-1, 3))
    criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 10000, 0.0001)
    flags = cv2.KMEANS_RANDOM_CENTERS

    for i in range(n_iterations):
        compactness, labels, centers = cv2.kmeans(samples, n_clusters, None, criteria, n_rodadas, flags)
        centers = np.uint8(centers)
        clustered_image = centers[labels.flatten()]
        clustered_image = clustered_image.reshape(image.shape)
        cv2.imshow("Clustered Image", clustered_image)
        cv2.imwrite(f"kmeans_image_{i}.png", clustered_image)
        print(f"Imagem {i + 1} salva como kmeans_image_{i}.png")

        if cv2.waitKey(0) == ord('q'):
            break

    cv2.destroyAllWindows()

def main():
    image_url = "https://img.freepik.com/free-photo/seafood-plate-with-shrimps-mussels-lobsters-served-with-lemon_140725-8798.jpg?w=740&amp;t=st=1719254482~exp=1719255082~hmac=36cdd489ec267993e8d9293c42b46cbe4b017f8b0548f6d258a71dbc001580dc"
    image = download_image(image_url)
    kmeans_clustering(image, n_clusters=8, n_iterations=10, n_rodadas=1)

if __name__ == "__main__":
    main()</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resultados_8">Resultados</h4>
<div class="imageblock">
<div class="content">
<img src="exercicios/k-means/images/allimgs.gif" alt="allimgs">
</div>
<div class="title">Figure 17. Equalização</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_13_extração_de_contornos">13 Extração de contornos</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_exercicio_13_1">Exercicio 13.1</h3>
<div class="paragraph">
<p>Utilizando o programa contornos.cpp como referência, aplique-o na extração do contorno da imagem retangulos.png mostrada na Figura 55, “Retângulos superpostos”. Quantos pontos são gerados para o contorno dos retângulos?</p>
</div>
<div class="sect3">
<h4 id="_solução_15">Solução</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2
import sys

def main(image_path):
    # Carrega a imagem em escala de cinza
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    if image is None:
        print(f"Não abriu {image_path}.")
        return

    # Aplica o limiar Otsu
    _, binary_image = cv2.threshold(image, 1, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # Encontra os contornos
    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

    # Converte a imagem para BGR
    color_image = cv2.cvtColor(binary_image, cv2.COLOR_GRAY2BGR)

    # Cria e escreve no arquivo SVG
    svg_path = "contornos.svg"
    with open(svg_path, 'w') as file:
        file.write(f'&lt;svg height="{image.shape[0]}" width="{image.shape[1]}" xmlns="http://www.w3.org/2000/svg"&gt;\n')
        for contour in contours:
            if len(contour) &gt; 0:
                file.write(f'&lt;path d="M {contour[0][0][0]} {contour[0][0][1]} ')
                for point in contour[1:]:
                    file.write(f'L {point[0][0]} {point[0][1]} ')
                file.write('Z" fill="none" stroke="black" stroke-width="1"/&gt;\n')
        file.write('&lt;/svg&gt;\n')

    # Desenha os contornos na imagem
    cv2.drawContours(color_image, contours, -1, (0, 0, 255), 1)

    # Mostra a imagem
    cv2.imshow('Imagem', color_image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

    # Imprime o número de pontos gerados para cada contorno
    for i, contour in enumerate(contours):
        print(f"Contorno {i + 1}: {len(contour)} pontos")

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Uso: python contornos.py &lt;caminho/para/sua/imagem&gt;")
    else:
        main(sys.argv[1])</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resultados_9">Resultados</h4>
<div class="imageblock">
<div class="content">
<img src="exercicios/momentos-contornos/svg-up.png" alt="svg up">
</div>
<div class="title">Figure 18. Resultado</div>
</div>
<div class="paragraph">
<p><a href="https://raw.githubusercontent.com/ruanlcs/PDI/39fbaa19f08fa8db98f86b312542bbeb63771f40/exercicios/momentos-contornos/contornos.svg">contornos.svg</a></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">Contorno 1: 746 pontos</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_exercicio_13_2">Exercicio 13.2</h3>
<div class="paragraph">
<p>Modifique o programa para extrair os contornos internos das componentes conectadas presentes na imagem formas.png. Para isso, altere o parâmetro cv::CHAIN_APPROX_NONE para cv::CHAIN_APPROX_SIMPLE na função findContours(). O que acontece com os novos contornos extraídos? Mostre quantos pontos são gerados após a alteração e discuta como a modificação do parâmetro cv::CHAIN_APPROX_SIMPLE influencia na extração do contorno.</p>
</div>
<div class="sect3">
<h4 id="_solução_16">Solução</h4>
<div class="paragraph">
<p>Após a modificação o total que era de 10182 pontos nos contornos, agora passou a ser 6049. É possível concluir que os momentos Hu (hu[0] a hu[6]) fornecem informações sobre as propriedades geométricas para cada contorno:
hu[0]: Representa a compressão geral da forma.
hu[1] e hu[2]: captura a orientação do contorno.
hu[3] a hu[6]: reflete características de forma de ordem superior, como assimetria e curvatura.
Ao comparar os contornos rotulados com seus respectivos momentos Hu, foi possível também observar como esses momentos descrevem e diferenciam quantitativamente as formas presentes na imagem.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2
import numpy as np

def main(image_path):
    # Carrega a imagem em escala de cinza
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    if image is None:
        print(f"Não abriu {image_path}.")
        return

    # Aplica limiarização
    _, thresholded = cv2.threshold(image, 1, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU + cv2.THRESH_BINARY_INV)

    # Encontra contornos
    contours, hierarchy = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Converte a imagem de volta para BGR para desenhar colorido
    image_color = cv2.cvtColor(thresholded, cv2.COLOR_GRAY2BGR)

    nformas = 0
    total_pontos = 0

    for i, contour in enumerate(contours):
        if len(contour) &lt; 10:
            continue

        nformas += 1
        total_pontos += len(contour)  # Conta o número de pontos no contorno

        momentos = cv2.moments(contour)
        center = (int(momentos['m10'] / momentos['m00']), int(momentos['m01'] / momentos['m00']))

        hu = cv2.HuMoments(momentos).flatten()
        if hu[0] &gt; 0:
            cv2.drawContours(image_color, [contour], -1, (0, 0, 255), 2)
        else:
            cv2.drawContours(image_color, [contour], -1, (0, 255, 0), 2)

        cv2.putText(image_color, str(i), center, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 8)
        cv2.putText(image_color, str(i), center, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

    print(f"Número de objetos: {nformas}")
    print(f"Total de pontos nos contornos: {total_pontos}")

    # Mostra a imagem resultante
    cv2.imshow("janela", image_color)
    cv2.imwrite("contornos-rotulados.png", image_color)
    cv2.waitKey()

if __name__ == "__main__":
    import sys
    if len(sys.argv) != 2:
        print("Uso: python script.py &lt;caminho/para/sua/imagem&gt;")
    else:
        main(sys.argv[1])</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resultados_10">Resultados</h4>
<div class="imageblock">
<div class="content">
<img src="exercicios/momentos-contornos/contornos-rotulados.png" alt="contornos rotulados">
</div>
<div class="title">Figure 19. Resultado</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">Número de objetos: 23
Total de pontos nos contornos: 6049</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Momentos.txt</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-txt hljs" data-lang="txt">3, 0.7980456544500546, 5.002818126688723, 8.66349372899882, 12.146783568271973, -22.554558416173816, 14.977920155016884, -23.511127023443294,
5, 0.798075648949325, 5.196825763982868, 6.910769337344917, 11.44419800902539, -20.991604616472397, -14.380879700490073, -20.66531423640748,
7, -0.08695390667730801, -0.15788678609512896, 1.4955502072567566, 1.683300361471716, 3.2727335891599134, 1.6045397958952095, -5.491105637701256,
8, -0.12013098365240334, -0.2286356101177591, 1.25615150963532, 1.3510385362156954, 2.654641066763785, 1.2369603568267795, 4.8852632547869685,
9, 0.373822801613905, 0.8201741384420282, 4.122326179612827, 4.44221370599208, 8.730458659575255, 4.891286069309689, 9.507672115101547,
10, 0.37147351008111845, 0.8232495552887015, 3.120957486991877, 3.35500160919377, 6.592987092658788, 3.766757734021516, -8.874637303868962,
11, -0.12954381828086417, -0.2437062677345215, 1.0071672017356563, 1.1373690388688276, 2.2096426940958076, 1.015634920141384, 4.50646122450822,
12, 0.7980084623326414, 4.865669195872324, 7.608334393591508, 11.645637297350737, -21.578627424744756, -15.527277840988514, -21.333459419267847,
13, 0.3347083682781399, 0.736686337851901, 2.7830442728267943, 2.964711062675534, 5.838590055975617, 3.33305423291522, 8.44576867104349,
14, -0.10672173861184883, -0.19606114646466194, 1.0561733184953725, 1.1995516258250118, 2.3274245840053727, 1.101619075625358, -4.485491154447043,
15, -0.09588127397860521, -0.17262078445594184, 0.989909395305192, 1.1317109512020274, 2.192551724451677, 1.0458844607583004, 4.118052896956238,
16, -0.032082954686877635, -0.04503226169870226, 1.3417819116976524, 1.4833929891085882, 2.8959919181459526, 1.4610948739123788, -5.034418227760792,
17, 0.7980516236250226, 5.093255641006368, 7.9730399679617046, 13.564592650151068, -24.36737189734703, -16.274963962875677, 24.753043671775824,
18, -0.10770799319933044, -0.2009824995901248, 1.3727729230667802, 1.526796787286399, 2.976604809739585, 1.4266017003142581, -4.962532891924834,
19, 0.7980842977979631, 5.3055384470951115, 6.735451807461803, 11.10480385951502, 20.128556520817597, 13.922815915922069, -20.23533279987061,
20, 0.340446158504866, 0.74834059677944, 2.873151147133867, 3.057539520478188, 6.022885031121973, 3.4317382501806075, -9.067474600645115,
21, -0.1108404052158676, -0.20467389148656034, 1.0629142092623385, 1.2070521573725663, 2.3420354500008647, 1.104721073150821, 5.491080924771011,
24, -0.058188083571502416, -0.09518697945646949, 1.4700820382426598, 1.7038785620651216, 3.2908666879535104, 1.6563214147452765, -5.512477378088148,
25, 0.7980633445581101, 5.110584871111505, 8.003787138995612, 12.474960783755675, -23.804039202234303, 15.811154495695433, -22.715776150080973,
26, 0.36968655771189635, 0.8169750436376623, 3.27875640906847, 3.500280679086962, 6.89012365689932, 3.911474862764768, -8.302775574724764,
27, -0.0011739537036063968, 0.019307012713260647, 1.5024188745879958, 1.6722586309260392, 3.2595975278823865, 1.6819126088093443, 6.34849299286992,
28, 0.36236268890882795, 0.792964669093222, 3.9969195013152925, 4.223198412108661, 8.333501330458834, 4.621455093161515, 9.808095725551961,
29, 0.3386752421181225, 0.7380611554483857, 3.851425129831454, 4.038965703772819, 7.984441494966377, 4.413301564934962, -9.4288092785474,</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_14_filtragem_de_forma_com_morfologia_matemática">14 Filtragem de forma com morfologia matemática</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_exercicio_4">Exercicio</h3>
<div class="paragraph">
<p>Usando o programa morfologia.cpp como referência, criar um programa que resolva o problema da pré-filtragem de forma para reconhecimento dos caracteres usando operações morfológicas. Usar as imagens:
<a href="https://agostinhobritojr.github.io/tutorial/pdi/figs/digitos-1.png">digitos-1.png</a>, <a href="https://agostinhobritojr.github.io/tutorial/pdi/figs/digitos-2.png">digitos-2.png</a>, <a href="https://agostinhobritojr.github.io/tutorial/pdi/figs/digitos-3.png">digitos-3.png</a>, <a href="https://agostinhobritojr.github.io/tutorial/pdi/figs/digitos-4.png">digitos-4.png</a> e <a href="https://agostinhobritojr.github.io/tutorial/pdi/figs/digitos-5.png">digitos-5.png</a> para testar o programa. Ter cuidado para deixar o ponto decimal separado dos demais dígitos para evitar um reconhecimento errado do número no visor.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="exercicios/transform/antes.png" alt="antes">
</div>
<div class="title">Figure 20. Caracteres do visor</div>
</div>
<div class="sect3">
<h4 id="_solução_17">Solução</h4>
<div class="paragraph">
<p>Para resolver esse problema, foi utilizado a operação de fechamento morfológico, que envolve a aplicação de uma dilatação seguida de uma erosão na imagem. O elemento estruturante é um retângulo capaz de unir as descontinuidades dos números nos displays. No entanto, como as operações morfológicas do OpenCV funcionam em elementos de cor branca, é necessário primeiro inverter as cores da imagem (fazer o negativo). Após aplicar as operações morfológicas, inverte-se novamente a imagem para restaurar a cor original dos dígitos.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2
import numpy as np

def apply_morphology(image, str_element):
    # Aplica dilatação seguida de erosão
    dilated = cv2.dilate(image, str_element)
    eroded = cv2.erode(dilated, str_element)
    # Inverte a imagem para obter o resultado final desejado
    return cv2.bitwise_not(eroded)

def main():
    # Carrega as imagens
    images = []
    for i in range(1, 6):
        filename = f"digitos-{i}.png"
        img = cv2.imread(filename, cv2.IMREAD_UNCHANGED)
        if img is None:
            print(f"Erro ao carregar a imagem: {filename}")
            return -1
        images.append(img)

    # Inverte as cores das imagens
    for i in range(5):
        images[i] = cv2.bitwise_not(images[i])

    # Elemento estruturante
    str_element = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 15))

    # Aplica operações de morfologia para cada imagem
    result_images = []
    for i in range(5):
        result = apply_morphology(images[i], str_element)
        result_images.append(result)
        cv2.imwrite(f"morfologia{i+1}.png", result)

    cv2.waitKey(0)
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resultados_11">Resultados</h4>
<div class="imageblock">
<div class="content">
<img src="exercicios/transform/morfologia1.png" alt="morfologia1">
</div>
<div class="title">Figure 21. Morfologia1</div>
</div>
<div class="imageblock">
<div class="content">
<img src="exercicios/transform/morfologia2.png" alt="morfologia2">
</div>
<div class="title">Figure 22. Morfologia2</div>
</div>
<div class="imageblock">
<div class="content">
<img src="exercicios/transform/morfologia3.png" alt="morfologia3">
</div>
<div class="title">Figure 23. Morfologia3</div>
</div>
<div class="imageblock">
<div class="content">
<img src="exercicios/transform/morfologia4.png" alt="morfologia4">
</div>
<div class="title">Figure 24. Morfologia4</div>
</div>
<div class="imageblock">
<div class="content">
<img src="exercicios/transform/morfologia5.png" alt="morfologia5">
</div>
<div class="title">Figure 25. Morfologia5</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2024-07-24 19:39:54 -0300
</div>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.3/highlight.min.js"></script>
<script>
if (!hljs.initHighlighting.called) {
  hljs.initHighlighting.called = true
  ;[].slice.call(document.querySelectorAll('pre.highlight > code[data-lang]')).forEach(function (el) { hljs.highlightBlock(el) })
}
</script>
</body>
</html>